So far, we have studied how neural nets are powerful tools for prediction and classification. Can we also apply them to generation?

In this section, we will learn about Generative Adversarial Nets, and how they can be used to generate realistic-looking images from scratch.




How can we make a neural net generative? Neural nets are **deterministic**, that is, they will always give the same output if you feed them the same input.

Rather than introducing randomness into the network itself, which would cause problems in backpropagation, we instead sample our input \(z\) from a distribution \(p_z(z)\), normally a multivariate unit Gaussian (chosen for mathematical convenience).

Once we have sampled our input from this distribution, we want to run it through our Generative network to get something that appears realistic. Let's denote the output from the Generator on \(z\) to be \(G(z)\).

How should we define our loss function for the Generative network?



A Discriminator network is used to attempt to distinguish samples created by the Generator and samples from the real world.

Let's now define some notation: let \(x\) represent a sample from the real world, and let \(p_x\) be the true distribution of real-world possibilities. Let \(D(k)\) be the output of the Discriminator on some sample \(k\), the probability that \(k\) is from the real world (not created by the generator).

Now, suppose that we have some \(x\) sampled from the real world. Which of the loss functions for \(D(x)\) pictured below makes sense?

1) ![](https://raw.githubusercontent.com/alvinzz/brilliant-ann/master/5-2-3-1.png)
2) ![](https://raw.githubusercontent.com/alvinzz/brilliant-ann/master/5-2-3-2.png)
3) ![](https://raw.githubusercontent.com/alvinzz/brilliant-ann/master/5-2-3-3.png)
4) ![](https://raw.githubusercontent.com/alvinzz/brilliant-ann/master/5-2-3-4.png)



Now, for samples \(x\) drawn from the real world, we define the loss function of the Discriminator to be \(-\log(D(x))\), whereas for samples \(G(z)\) created by the Generator, the loss function is \(-
